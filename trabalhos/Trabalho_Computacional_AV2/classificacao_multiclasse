# Imports
import numpy as np
import matplotlib.pyplot as plt
from modelos_RNA.adaline import Adaline
from modelos_RNA.multi_layer_perceptron import MLP
from config import Config
import csv

coluna_vertebral = None
with open("trabalhos\\Trabalho_Computacional_AV2\\datasets\\coluna_vertebral.csv", newline='') as csvfile:
    reader = csv.reader(csvfile)
    coluna_vertebral = np.array(list(reader))
# Classificação com múltiplas classes
#coluna_vertebral = np.genfromtxt("trabalhos\\Trabalho_Computacional_AV2\\datasets\\coluna_vertebral.csv", delimiter=",", dtype=None, encoding='utf-8')
# Separação das variável dependente e independentes
X = coluna_vertebral[:, :-1]  # Variável independente (todas as colunas menos a última)
# Converte X para float
X = X.astype(float)

y = coluna_vertebral[:, -1]   # Variável dependente (última coluna)
y = y.reshape(-1, 1) # Reshape para 1 coluna

y = np.where(y == 'NO', [+1, -1, -1], y) # Normal
y = np.where(y == 'DH', [-1, +1, -1], y) # Disk hernia
y = np.where(y == 'SL', [-1, -1, +1], y) # Spondylolisthesis

# Converte y para float
y = y.astype(float)

# Normalização dos dados
X = (X - np.min(X)) / (np.max(X) - np.min(X))

for round in range(Config.CLASSIFICATION_N_ROUNDS):
    # Instanciando os modelos
    adaline = Adaline(η=Config.CLASSIFICATION_LEARNING_RATE, ϵ=Config.CLASSIFICATION_EPSILON, epochs=Config.CLASSIFICATION_EPOCHS)
    mlp = MLP(input_size=6, q=[32, 16], m=3, η=Config.CLASSIFICATION_LEARNING_RATE, ϵ=Config.CLASSIFICATION_EPSILON, tolleration=10, epochs=Config.CLASSIFICATION_EPOCHS)
    print(f"Rodada: {round + 1}")
    # Aleatorização dos dados
    index = np.random.permutation(coluna_vertebral.shape[0])
    X_shuffled = X[index]
    y_shuffled = y[index]
    # Separação dos dados em treino, teste e validação
    train_size = int(Config.CLASSIFICATION_TRAIN * len(X))
    validation_size = int(Config.CLASSIFICATION_VALIDATION * len(X))
    # 80% para treino
    X_train = X_shuffled[:train_size]
    y_train = y_shuffled[:train_size]
    # 20% para teste
    X_test = X_shuffled[train_size:]
    y_test = y_shuffled[train_size:]
    # 10% para validação
    X_validation = X_test[:validation_size]
    y_validation = y_test[:validation_size]
    # Etapa de treinamento
    # adaline.fit(X_train, y_train)
    mlp.train_classification(X_train, y_train, X_validation, y_validation)
    # Etapa de teste
    mlp_predictions = []
    for x in X_test:
        x = np.hstack([[-1], x])
        mlp_predictions.append(mlp.predict(x))


# if Config.CLASSIFICATION_PLOT_GRAPH:
#     # Faz o plot 3d dos dados
#     fig = plt.figure(0)
#     ax = fig.add_subplot(111, projection='3d')
#     ax.set_title('Dados Originais')
#     ax.set_xlabel('X1')
#     ax.set_ylabel('X2')
#     ax.set_zlabel('X3')
#     ax.scatter(X[:, 0], X[:, 1], X[:, 2], c=y, cmap='viridis', label='Dados Originais')